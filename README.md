# Grammarly Support Chatbot with TensorZero

A production-ready customer support chatbot built with LangGraph and optimized using TensorZero. This application demonstrates how to build an AI-powered support system that improves over time through automated optimization techniques.

## ğŸš€ Features

- **Intent Classification**: Automatically categorizes customer queries into support categories
- **Intelligent Response Generation**: Provides helpful, context-aware responses
- **Self-Optimization**: Uses TensorZero for continuous improvement through:
  - Dynamic In-Context Learning (DICL)
  - Automated prompt engineering (MIPRO)
  - Supervised fine-tuning
- **Human Escalation**: Intelligently identifies when human support is needed
- **Performance Tracking**: Comprehensive metrics and visualization
- **LangGraph Studio Compatible**: Visual debugging and testing

## ğŸ“‹ Prerequisites

- Docker and Docker Compose
- Python 3.11+
- OpenAI API key
- At least 4GB of available RAM

## ğŸ› ï¸ Setup

### 1. Clone and Navigate

```bash
cd /home/alchen/claude/grammarly-tz
```

### 2. Environment Configuration

```bash
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

### 3. Launch Services

```bash
docker-compose up -d
```

This starts:
- **ClickHouse**: Data storage for TensorZero (port 8123)
- **TensorZero Gateway**: LLM gateway and optimization engine (port 3000)
- **TensorZero UI**: Monitoring and optimization interface (port 4000)
- **LangGraph App**: The chatbot application (port 8000)

### 4. Verify Services

```bash
# Check health
curl http://localhost:8000/health

# Access UIs
# TensorZero UI: http://localhost:4000
# API Docs: http://localhost:8000/docs
```

## ğŸ“Š Data Collection & Training

### 1. Scrape Help Articles (Optional)

```bash
cd scripts
python scrape_grammarly_help.py
```

### 2. Generate Training Dataset

```bash
python generate_dataset.py
```

This creates synthetic customer queries with:
- Diverse intents (technical support, billing, features, etc.)
- Structured JSON outputs for training
- Train/validation/test splits

## ğŸ§ª Using the Chatbot

### Via API

```python
import httpx

response = httpx.post("http://localhost:8000/chat", json={
    "query": "I can't get Grammarly to work in Google Docs",
    "user_context": {
        "platform": "chrome",
        "product": "grammarly_premium"
    }
})

print(response.json())
```

### Via LangGraph Studio

1. Install LangGraph Studio
2. Open the project directory
3. The entry point is configured in `langgraph/app.py`

## ğŸ”§ Optimization Workflow

### 1. Collect Initial Data

Run the chatbot with baseline variants to collect inference data:

```bash
# The app randomly samples between gpt-4o and gpt-4o-mini
# All inferences are automatically logged to ClickHouse
```

### 2. Apply DICL (Dynamic In-Context Learning)

DICL automatically selects relevant examples from successful interactions:

```bash
# Data is automatically used by the gpt_4o_mini_dicl variant
# No manual intervention needed
```

### 3. Run MIPRO Optimization

For automated prompt engineering:

```bash
cd /home/alchen/claude/tensorzero/recipes/mipro
python mipro.ipynb  # Adapt for this use case
```

### 4. Supervised Fine-Tuning

Use the TensorZero UI (http://localhost:4000) to:
1. Navigate to "Supervised Fine-Tuning"
2. Select function and metrics
3. Start fine-tuning job
4. Add the fine-tuned model to `config/tensorzero.toml`

## ğŸ“ˆ Evaluation & Monitoring

### Run Evaluation

```bash
cd scripts
python evaluate_variants.py
```

This generates:
- Performance comparison charts
- Detailed metrics (accuracy, latency, quality)
- Recommendations for production deployment

### View Results

Results are saved to `data/results/`:
- `variant_comparison.png`: Visual performance comparison
- `evaluation_metrics.csv`: Detailed metrics
- `evaluation_report.json`: Summary and recommendations

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LangGraph     â”‚â”€â”€â”€â”€â–¶â”‚   TensorZero     â”‚â”€â”€â”€â”€â–¶â”‚    OpenAI       â”‚
â”‚   Application   â”‚     â”‚    Gateway       â”‚     â”‚    Models       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â”‚                       â–¼
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚              â”‚   ClickHouse    â”‚
         â”‚              â”‚   (Metrics)     â”‚
         â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LangGraph      â”‚
â”‚  Checkpointer   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
grammarly-tz/
â”œâ”€â”€ config/               # TensorZero configuration
â”‚   â”œâ”€â”€ tensorzero.toml  # Main config with functions/variants
â”‚   â””â”€â”€ functions/       # Prompt templates and schemas
â”œâ”€â”€ langgraph/           # LangGraph application
â”‚   â”œâ”€â”€ app.py          # Main graph definition
â”‚   â”œâ”€â”€ nodes.py        # Processing nodes
â”‚   â”œâ”€â”€ state.py        # State management
â”‚   â””â”€â”€ server.py       # FastAPI wrapper
â”œâ”€â”€ scripts/             # Data and evaluation scripts
â”‚   â”œâ”€â”€ scrape_grammarly_help.py
â”‚   â”œâ”€â”€ generate_dataset.py
â”‚   â””â”€â”€ evaluate_variants.py
â”œâ”€â”€ utils/               # Shared utilities
â”‚   â””â”€â”€ tensorzero_client.py
â”œâ”€â”€ data/                # Data storage
â”‚   â”œâ”€â”€ scraped/        # Help articles
â”‚   â”œâ”€â”€ processed/      # Training datasets
â”‚   â””â”€â”€ results/        # Evaluation outputs
â”œâ”€â”€ docker-compose.yml   # Service orchestration
â”œâ”€â”€ Dockerfile          # App container
â””â”€â”€ requirements.txt    # Python dependencies
```

## ğŸ¯ Key Concepts

### Variants

The system tests multiple model variants:
- **gpt_4o**: High-quality baseline
- **gpt_4o_mini**: Cost-effective option
- **gpt_4o_mini_dicl**: With dynamic examples
- **gpt_4o_mini_fine_tuned**: After training

### Metrics

- **intent_accuracy**: Classification accuracy
- **response_relevance**: Response quality (0-1)
- **resolution_potential**: Can resolve without human
- **customer_satisfaction**: Predicted satisfaction

### Optimization Strategies

1. **Baseline**: Collect data with standard prompts
2. **DICL**: Use successful examples dynamically
3. **MIPRO**: Optimize prompts algorithmically
4. **Fine-tuning**: Train custom models

## ğŸ” Troubleshooting

### Services Won't Start

```bash
# Check logs
docker-compose logs tensorzero
docker-compose logs clickhouse

# Restart services
docker-compose down
docker-compose up -d
```

### API Errors

- Verify OpenAI API key is set correctly
- Check TensorZero Gateway health: `curl http://localhost:3000/health`
- Ensure ClickHouse is running: `docker-compose ps`

### Performance Issues

- Increase Docker memory allocation
- Use `gpt_4o_mini` variants for faster responses
- Enable response streaming in production

## ğŸš€ Production Deployment

1. **Security**: Use environment-specific secrets
2. **Scaling**: Deploy TensorZero Gateway behind a load balancer
3. **Monitoring**: Set up alerts for error rates and latency
4. **Backup**: Regular ClickHouse backups for inference data
5. **A/B Testing**: Use TensorZero's variant weights for gradual rollout

## ğŸ“š Next Steps

1. **Expand Dataset**: Add more query patterns and edge cases
2. **Multi-turn Conversations**: Enhance context handling
3. **RAG Integration**: Connect to Grammarly's knowledge base
4. **Custom Metrics**: Add business-specific success metrics
5. **Multi-language Support**: Extend to non-English queries
